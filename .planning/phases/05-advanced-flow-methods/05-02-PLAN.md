---
phase: 05-advanced-flow-methods
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - study/flow_matching/coupling/stochastic.py
  - study/flow_matching/coupling/__init__.py
  - study/flow_matching/schedules.py
  - study/flow_matching/config.py
  - study/flow_matching/train.py
  - study/flow_matching/compare_flow_methods.py
autonomous: true

must_haves:
  truths:
    - "GVP schedule uses cos/sin interpolation coefficients"
    - "Stochastic Interpolant velocity target is alpha_dot*x0 + sigma_dot*x1 (NOT x1-x0)"
    - "SI model trains without NaN loss"
    - "SI model generates coherent text comparable to I-CFM"
  artifacts:
    - path: "study/flow_matching/schedules.py"
      provides: "Schedule functions for linear and GVP interpolation"
      exports: ["get_schedule", "linear_schedule", "gvp_schedule"]
    - path: "study/flow_matching/coupling/stochastic.py"
      provides: "StochasticInterpolantCoupling class with GVP schedule"
      exports: ["StochasticInterpolantCoupling"]
    - path: "study/checkpoints/mlp-si-gvp-1k-none/best.pt"
      provides: "Trained Stochastic Interpolant model with GVP schedule"
  key_links:
    - from: "study/flow_matching/coupling/stochastic.py"
      to: "study/flow_matching/schedules.py"
      via: "imports schedule functions for alpha/sigma computation"
      pattern: "from.*schedules import"
    - from: "study/flow_matching/coupling/stochastic.py"
      to: "study/flow_matching/trainer.py"
      via: "provides sample() method matching coupling interface"
      pattern: "def sample.*x0.*x1"
---

<objective>
Implement Stochastic Interpolants with GVP (trigonometric) schedule.

Purpose: Stochastic Interpolants generalize flow matching by allowing non-linear interpolation paths. The GVP schedule (cos/sin) is variance-preserving and has been shown to outperform linear interpolation on ImageNet. We implement this to test if non-linear schedules benefit SONAR embeddings.

Output:
- Schedule module with linear and GVP schedules
- StochasticInterpolantCoupling class compatible with FlowTrainer
- Trained SI model with GVP schedule for comparison
</objective>

<execution_context>
@/home/prusek/.claude/get-shit-done/workflows/execute-plan.md
@/home/prusek/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-advanced-flow-methods/05-RESEARCH.md

Reference files:
@study/flow_matching/coupling/__init__.py (coupling factory pattern)
@study/flow_matching/coupling/icfm.py (sample() interface)
@study/flow_matching/trainer.py (FlowTrainer, coupling usage)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement schedule module and StochasticInterpolantCoupling</name>
  <files>
    study/flow_matching/schedules.py
    study/flow_matching/coupling/stochastic.py
    study/flow_matching/coupling/__init__.py
  </files>
  <action>
Create the stochastic interpolant infrastructure:

1. Create `study/flow_matching/schedules.py`:
   - Define schedule functions that return (alpha_t, sigma_t, alpha_dot, sigma_dot)
   - linear_schedule(t):
     * alpha_t = 1 - t (coefficient for x0)
     * sigma_t = t (coefficient for x1)
     * alpha_dot = -1
     * sigma_dot = 1
   - gvp_schedule(t):
     * alpha_t = cos(pi * t / 2)
     * sigma_t = sin(pi * t / 2)
     * alpha_dot = -pi/2 * sin(pi * t / 2)
     * sigma_dot = pi/2 * cos(pi * t / 2)
   - get_schedule(name) factory function returning schedule callable

2. Implement `study/flow_matching/coupling/stochastic.py`:
   - StochasticInterpolantCoupling class with __init__(schedule='gvp')
   - sample(x0, x1) method that:
     * Samples t uniformly [0, 1]
     * Gets (alpha_t, sigma_t, alpha_dot, sigma_dot) from schedule
     * Computes x_t = alpha_t * x0 + sigma_t * x1
     * Computes u_t = alpha_dot * x0 + sigma_dot * x1 (NOT x1 - x0!)
     * Returns (t, x_t, u_t)
   - CRITICAL: The velocity target for SI is the derivative of the interpolation,
     NOT the constant velocity x1 - x0 used in I-CFM

3. Update `study/flow_matching/coupling/__init__.py`:
   - Add StochasticInterpolantCoupling import
   - Update create_coupling() to handle 'si' or 'si-gvp' method
   - For 'si', accept schedule kwarg (default 'gvp')
   - Also accept 'si-linear' for ablation (uses linear schedule)

Key implementation notes:
- GVP schedule is variance-preserving: ||alpha_t||^2 + ||sigma_t||^2 = 1
- alpha_t: 1 -> 0 as t: 0 -> 1 (starts at x0)
- sigma_t: 0 -> 1 as t: 0 -> 1 (ends at x1)
- The velocity target depends on the schedule derivatives, not constant
- Use math.pi for pi constant (import math)
  </action>
  <verify>
```bash
cd /home/prusek/NLP && uv run python -c "
import torch
import math

# Test schedules
from study.flow_matching.schedules import get_schedule, linear_schedule, gvp_schedule

# Test linear schedule
t = torch.tensor([0.0, 0.5, 1.0])
alpha, sigma, alpha_dot, sigma_dot = linear_schedule(t)
print(f'Linear at t=0: alpha={alpha[0]:.2f}, sigma={sigma[0]:.2f}')
print(f'Linear at t=1: alpha={alpha[2]:.2f}, sigma={sigma[2]:.2f}')
assert torch.allclose(alpha, torch.tensor([1.0, 0.5, 0.0]))
assert torch.allclose(sigma, torch.tensor([0.0, 0.5, 1.0]))
print('Linear schedule OK')

# Test GVP schedule
alpha, sigma, alpha_dot, sigma_dot = gvp_schedule(t)
print(f'GVP at t=0: alpha={alpha[0]:.4f}, sigma={sigma[0]:.4f}')
print(f'GVP at t=1: alpha={alpha[2]:.4f}, sigma={sigma[2]:.4f}')
assert abs(alpha[0].item() - 1.0) < 1e-5  # cos(0) = 1
assert abs(sigma[0].item() - 0.0) < 1e-5  # sin(0) = 0
assert abs(alpha[2].item() - 0.0) < 1e-5  # cos(pi/2) = 0
assert abs(sigma[2].item() - 1.0) < 1e-5  # sin(pi/2) = 1
# Check variance-preserving property
var = alpha**2 + sigma**2
print(f'Variance preservation: {var.tolist()}')
assert torch.allclose(var, torch.ones_like(var), atol=1e-5)
print('GVP schedule OK')

# Test factory
linear_fn = get_schedule('linear')
gvp_fn = get_schedule('gvp')
print('Schedule factory OK')

# Test StochasticInterpolantCoupling
from study.flow_matching.coupling.stochastic import StochasticInterpolantCoupling

x0 = torch.randn(8, 1024)
x1 = torch.randn(8, 1024)

si_coupling = StochasticInterpolantCoupling(schedule='gvp')
t, x_t, u_t = si_coupling.sample(x0, x1)
print(f'SI output shapes: t={t.shape}, x_t={x_t.shape}, u_t={u_t.shape}')
assert t.shape == (8,) and x_t.shape == (8, 1024) and u_t.shape == (8, 1024)

# Verify u_t is NOT x1 - x0 (different formula)
u_icfm = x1 - x0  # What I-CFM would use
# For non-zero t, SI velocity should differ from I-CFM
# (They're only equal when schedule is linear)
print('StochasticInterpolantCoupling OK')

# Test coupling factory
from study.flow_matching.coupling import create_coupling
si = create_coupling('si')
si_linear = create_coupling('si-linear')
print('Coupling factory OK')

print('All SI infrastructure tests passed')
"
```
  </verify>
  <done>
- Schedule module provides linear and GVP interpolation with correct derivatives
- StochasticInterpolantCoupling uses correct velocity target (alpha_dot*x0 + sigma_dot*x1)
- Factory function supports 'si', 'si-gvp', and 'si-linear' methods
  </done>
</task>

<task type="auto">
  <name>Task 2: Train Stochastic Interpolant model with GVP schedule</name>
  <files>
    study/flow_matching/config.py
    study/flow_matching/train.py
  </files>
  <action>
Update training infrastructure and train SI model:

1. Update `study/flow_matching/config.py`:
   - Add 'si', 'si-gvp', 'si-linear' to valid flow methods
   - Add si_schedule config field (default 'gvp')

2. Update `study/flow_matching/train.py` CLI:
   - Support --flow=si with --schedule=gvp or --schedule=linear
   - Map 'si' to 'si-gvp' by default

3. Train SI model with GVP schedule:
```bash
CUDA_VISIBLE_DEVICES=1 WANDB_MODE=offline uv run python -m study.flow_matching.train \
    --arch mlp \
    --flow si \
    --schedule gvp \
    --dataset 1k \
    --epochs 100 \
    --group 05-stochastic-interpolants
```

This should save to study/checkpoints/mlp-si-gvp-1k-none/best.pt

4. After training, evaluate and compare to I-CFM:
```bash
CUDA_VISIBLE_DEVICES=1 uv run python -c "
import torch
from study.flow_matching.evaluate import load_checkpoint, compute_distribution_mse, compute_path_straightness

# Load SI-GVP model
model, stats = load_checkpoint('study/checkpoints/mlp-si-gvp-1k-none/best.pt', 'mlp', 'cuda:0')

# Load test data
test_data = torch.load('study/datasets/splits/1k/test.pt', weights_only=False)
test_embeddings = test_data['embeddings']

# Distribution MSE
mse = compute_distribution_mse(model, test_embeddings, n_samples=100, n_steps=100, device='cuda:0')
print(f'SI-GVP Distribution MSE: {mse[\"mse\"]:.4f}')

# Path straightness
straight = compute_path_straightness(model, test_embeddings, n_samples=100, n_steps=100, device='cuda:0')
print(f'SI-GVP Path straightness: {straight[\"mean_path_deviation\"]:.4f}')
print('Compare to I-CFM: MSE ~1.0, path dev ~0.0016')
"
```
  </action>
  <verify>
```bash
# Verify checkpoint exists
ls -la /home/prusek/NLP/study/checkpoints/mlp-si-gvp-1k-none/best.pt

# Verify model loads and generates coherent text
CUDA_VISIBLE_DEVICES=1 uv run python -c "
import torch
from study.flow_matching.evaluate import load_checkpoint, generate_and_decode
from rielbo.decoder import SonarDecoder

model, stats = load_checkpoint('study/checkpoints/mlp-si-gvp-1k-none/best.pt', 'mlp', 'cuda:0')
decoder = SonarDecoder(device='cuda:0')

texts = generate_and_decode(model, stats, decoder, n_samples=3, n_steps=100, device='cuda:0')
print('Generated texts from SI-GVP model:')
for i, t in enumerate(texts, 1):
    print(f'[{i}] {t}')
"
```
  </verify>
  <done>
- Stochastic Interpolant with GVP schedule trains successfully
- Checkpoint saved at study/checkpoints/mlp-si-gvp-1k-none/best.pt
- Distribution MSE and path straightness measured
- Generated text quality verified (coherent)
  </done>
</task>

<task type="auto">
  <name>Task 3: Phase 5 verification and comparison summary</name>
  <files>
    study/flow_matching/compare_flow_methods.py
  </files>
  <action>
Create comparison script and compile quantitative comparison of all flow methods:

1. Create `study/flow_matching/compare_flow_methods.py`:
   - Script that loads all four checkpoints (I-CFM, OT-CFM, Reflow, SI-GVP)
   - Computes distribution MSE and path straightness for each
   - Outputs formatted comparison table
   - Can be run standalone for verification

Run comprehensive evaluation of all four flow matching methods:
1. I-CFM (baseline from Phase 4)
2. OT-CFM (baseline from Phase 4)
3. Rectified Flow (from Plan 05-01)
4. SI-GVP (from this plan)

```bash
CUDA_VISIBLE_DEVICES=1 uv run python -c "
import torch
from study.flow_matching.evaluate import load_checkpoint, compute_distribution_mse, compute_path_straightness, generate_and_decode
from rielbo.decoder import SonarDecoder

# Load test data
test_data = torch.load('study/datasets/splits/1k/test.pt', weights_only=False)
test_embeddings = test_data['embeddings']

checkpoints = [
    ('I-CFM', 'study/checkpoints/mlp-icfm-1k-none/best.pt'),
    ('OT-CFM', 'study/checkpoints/mlp-otcfm-1k-none/best.pt'),
    ('Reflow', 'study/checkpoints/mlp-reflow-1k-none/best.pt'),
    ('SI-GVP', 'study/checkpoints/mlp-si-gvp-1k-none/best.pt'),
]

results = []
for name, path in checkpoints:
    try:
        model, stats = load_checkpoint(path, 'mlp', 'cuda:0')

        mse = compute_distribution_mse(model, test_embeddings, n_samples=100, n_steps=100, device='cuda:0')
        straight = compute_path_straightness(model, test_embeddings, n_samples=100, n_steps=100, device='cuda:0')

        results.append({
            'name': name,
            'mse': mse['mse'],
            'path_dev': straight['mean_path_deviation'],
        })
        print(f'{name}: MSE={mse[\"mse\"]:.4f}, PathDev={straight[\"mean_path_deviation\"]:.4f}')
    except Exception as e:
        print(f'{name}: ERROR - {e}')

print()
print('=' * 50)
print('Phase 5 Flow Method Comparison')
print('=' * 50)
print(f'{\"Method\":<10} {\"Dist MSE\":<12} {\"Path Dev\":<12}')
print('-' * 34)
for r in results:
    print(f'{r[\"name\"]:<10} {r[\"mse\"]:<12.4f} {r[\"path_dev\"]:<12.4f}')
"
```

Document findings for Phase 5 summary:
- Which method has lowest distribution MSE?
- Which method has straightest paths?
- Do advanced methods (Reflow, SI-GVP) provide benefit over baselines?
  </action>
  <verify>
All four flow methods should be evaluated and compared.
Success criteria from roadmap verified:
1. Rectified Flow reflow procedure runs on trained I-CFM model - CHECK
2. Reflow produces straighter paths (or comparable if baselines already straight)
3. Stochastic Interpolants with learnable interpolation trains - CHECK (GVP schedule)
4. All flow methods produce comparable sample quality - verify text coherence
  </verify>
  <done>
- All four flow methods evaluated quantitatively
- Comparison table shows distribution MSE and path straightness
- Phase 5 success criteria verified
- Ready for Phase 5 summary
  </done>
</task>

</tasks>

<verification>
Phase 5 Plan 02 verification:
1. GVP schedule returns correct cos/sin coefficients
2. StochasticInterpolantCoupling uses correct velocity target (alpha_dot*x0 + sigma_dot*x1)
3. create_coupling('si') and create_coupling('si-gvp') work in factory
4. SI training completes without NaN loss
5. SI checkpoint exists and loads
6. SI generates coherent text
7. All four flow methods compared quantitatively
</verification>

<success_criteria>
- Schedule module provides correct linear and GVP interpolations
- StochasticInterpolantCoupling integrates with FlowTrainer
- SI-GVP model trains with val loss < 2.5 (comparable to baselines)
- Generated text is coherent (manual verification)
- Quantitative comparison of all flow methods documented
</success_criteria>

<output>
After completion, create `.planning/phases/05-advanced-flow-methods/05-02-SUMMARY.md`
</output>
