---
phase: 03-baseline-architectures
plan: 02
type: execute
wave: 2
depends_on: ["03-01"]
files_modified:
  - study/flow_matching/models/dit.py
  - study/flow_matching/models/__init__.py
autonomous: true

must_haves:
  truths:
    - "DiTVelocityNetwork with hidden_dim=384, num_layers=3, num_heads=6 has ~9.3M parameters"
    - "DiTVelocityNetwork forward(x, t) produces output shape [B, 1024]"
    - "create_model('dit') returns DiTVelocityNetwork instance"
    - "Both MLP and DiT train without NaN loss on 1K dataset"
    - "Generated embeddings decode to coherent text via SONAR"
  artifacts:
    - path: "study/flow_matching/models/dit.py"
      provides: "DiT velocity network with AdaLN-Zero conditioning"
      exports: ["DiTVelocityNetwork", "AdaLNBlock"]
    - path: "study/flow_matching/models/__init__.py"
      provides: "Extended model factory with DiT support"
      exports: ["create_model", "SimpleMLP", "DiTVelocityNetwork"]
  key_links:
    - from: "study/flow_matching/models/dit.py"
      to: "rielbo/velocity_network.py"
      via: "ported and scaled down"
      pattern: "AdaLNBlock"
    - from: "study/flow_matching/models/__init__.py"
      to: "study/flow_matching/models/dit.py"
      via: "import DiTVelocityNetwork"
      pattern: "from .dit import DiTVelocityNetwork"
---

<objective>
Port DiT velocity network from rielbo with scaled configuration (~9.3M params) and verify both architectures produce coherent text when decoded.

Purpose: Complete the baseline architecture set with an expressive DiT-style model for comparison, ensuring both baselines meet quality requirements (MSE < 0.1, coherent text output).

Output: DiTVelocityNetwork class in models/dit.py, extended model factory, verified training and text generation for both architectures.
</objective>

<execution_context>
@/home/prusek/.claude/get-shit-done/workflows/execute-plan.md
@/home/prusek/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-baseline-architectures/03-RESEARCH.md
@.planning/phases/03-baseline-architectures/03-01-SUMMARY.md
@rielbo/velocity_network.py
@study/flow_matching/models/__init__.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Port DiT velocity network from rielbo</name>
  <files>
    study/flow_matching/models/dit.py
    study/flow_matching/models/__init__.py
  </files>
  <action>
    1. Create dit.py by porting from rielbo/velocity_network.py:
       - Copy timestep_embedding function (or import from mlp.py to avoid duplication)
       - Copy AdaLNBlock class unchanged
       - Copy VelocityNetwork class, rename to DiTVelocityNetwork
       - Update default params for ~9.3M target:
         - hidden_dim=384 (was 512)
         - num_layers=3 (was 6)
         - num_heads=6 (was 8) - note: 384 / 6 = 64 per head (divisible)
       - Keep all other architecture details (AdaLN-Zero, zero-init, etc.)

    2. Update models/__init__.py:
       - Add: from .dit import DiTVelocityNetwork, AdaLNBlock
       - Extend create_model() to handle arch="dit":
         Return DiTVelocityNetwork with documented defaults
       - Update __all__ to include DiTVelocityNetwork, AdaLNBlock

    Note: Import timestep_embedding from mlp.py in dit.py to avoid duplication.
  </action>
  <verify>
    Run: python -c "
from study.flow_matching.models import create_model, DiTVelocityNetwork
import torch

# Test parameter count
m = create_model('dit')
p = sum(p.numel() for p in m.parameters())
print(f'DiTVelocityNetwork params: {p:,}')
assert 9_000_000 < p < 10_000_000, f'Param count {p} out of range'

# Test forward pass
x = torch.randn(4, 1024)
t = torch.rand(4)
v = m(x, t)
assert v.shape == (4, 1024), f'Output shape wrong: {v.shape}'
print('DiTVelocityNetwork verification passed')
"
  </verify>
  <done>DiTVelocityNetwork exists with ~9.3M params and correct forward signature</done>
</task>

<task type="auto">
  <name>Task 2: Verify both architectures train and decode</name>
  <files></files>
  <action>
    1. Run brief training for both architectures (2 epochs each):

       # MLP training
       CUDA_VISIBLE_DEVICES=1 WANDB_MODE=offline uv run python -m study.flow_matching.train \
         --arch mlp --flow icfm --dataset 1k --group baseline-verify --epochs 2

       # DiT training
       CUDA_VISIBLE_DEVICES=1 WANDB_MODE=offline uv run python -m study.flow_matching.train \
         --arch dit --flow icfm --dataset 1k --group baseline-verify --epochs 2

    2. For each trained model, run generation + decoding test:
       - Load checkpoint
       - Generate embeddings using simple Euler ODE integration (10 steps)
       - Denormalize using stats from datasets/VS_10k/normalization_stats.pt
       - Decode via SONAR decoder
       - Print 3 sample outputs

       Create a quick test script or run inline:
       python -c "
import torch
from study.flow_matching.models import create_model
from study.flow_matching.utils import load_checkpoint
from sonar.inference_pipelines.text import TextToEmbeddingModelPipeline

# ... generation and decoding code
"

    3. Verify:
       - No NaN in training
       - Loss decreases over 2 epochs
       - Decoded text is coherent (words, not gibberish)
       - Reconstruction MSE is reasonable (< 0.5 after just 2 epochs is fine for smoke test)
  </action>
  <verify>
    Both training runs complete with:
    - Finite loss values (no NaN)
    - Decreasing trend (epoch 2 <= epoch 1)
    - TRAINING COMPLETE message

    Decoding produces readable text (not garbled bytes).
  </verify>
  <done>Both MLP and DiT architectures train without NaN and produce decodable embeddings</done>
</task>

<task type="auto">
  <name>Task 3: Extended training and MSE verification</name>
  <files></files>
  <action>
    Run longer training (10 epochs minimum) on 5K dataset to verify:
    1. Loss continues to decrease
    2. Validation MSE < 0.1 is achievable (or on track)

    CUDA_VISIBLE_DEVICES=1 WANDB_MODE=offline uv run python -m study.flow_matching.train \
      --arch mlp --flow icfm --dataset 5k --group baseline-mse-check --epochs 10

    Then check the best validation loss from the training output.

    If val_loss > 0.1 after 10 epochs, that's OK for now - this is a smoke test.
    The key is that loss is decreasing and training is stable.

    Also run a quick generation test with the trained model to verify:
    - Sample 10 embeddings from noise
    - Compute MSE between generated and target embeddings
    - Decode and print 3 samples

    Document findings in the summary.
  </action>
  <verify>
    Training output shows:
    - No NaN throughout 10 epochs
    - Loss trend is decreasing
    - Best val loss is finite and reasonable (< 1.0)

    Generation test produces readable decoded text.
  </verify>
  <done>Extended training confirms stable optimization and reasonable MSE trajectory</done>
</task>

</tasks>

<verification>
1. DiTVelocityNetwork parameter count is in range [9M, 10M]
2. create_model('dit') returns DiTVelocityNetwork instance
3. Both architectures complete 2-epoch training without NaN
4. Generated embeddings decode to coherent English text
5. 10-epoch training shows decreasing loss trend
</verification>

<success_criteria>
- DiTVelocityNetwork ported with ~9.3M params
- Model factory supports both 'mlp' and 'dit' architectures
- Both architectures train without NaN loss
- Both produce embeddings that decode to coherent text
- Extended training shows stable optimization trajectory
</success_criteria>

<output>
After completion, create `.planning/phases/03-baseline-architectures/03-02-SUMMARY.md`
</output>
