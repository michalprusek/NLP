---
phase: 02-training-infrastructure
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - study/flow_matching/config.py
  - study/flow_matching/utils.py
  - study/flow_matching/trainer.py
autonomous: true

must_haves:
  truths:
    - "Training loop runs with EMA weight averaging"
    - "Gradients are clipped to max_norm=1.0"
    - "Training stops when validation loss stops improving for 20 epochs"
    - "Validation runs every epoch"
    - "Training runs on GPU 1 (A5000) via CUDA_VISIBLE_DEVICES=1"
  artifacts:
    - path: "study/flow_matching/config.py"
      provides: "TrainingConfig dataclass with stats_path field"
      contains: "dataclass"
    - path: "study/flow_matching/utils.py"
      provides: "EarlyStopping, EMAModel, cosine schedule"
      exports: ["EarlyStopping", "EMAModel", "get_cosine_schedule_with_warmup"]
    - path: "study/flow_matching/trainer.py"
      provides: "FlowTrainer class with train/validate methods"
      contains: "class FlowTrainer"
  key_links:
    - from: "study/flow_matching/trainer.py"
      to: "study/flow_matching/utils.py"
      via: "imports EarlyStopping, EMAModel"
      pattern: "from.*utils import"
    - from: "study/flow_matching/trainer.py"
      to: "study/data/dataset.py"
      via: "uses FlowDataset and create_dataloader"
      pattern: "from study.data.dataset import"
    - from: "study/flow_matching/config.py"
      to: "study/datasets/normalization_stats.pt"
      via: "stats_path field for loading normalization stats"
      pattern: "stats_path"
---

<objective>
Create core training infrastructure with EMA, gradient clipping, early stopping, and cosine annealing scheduler.

Purpose: Establish the foundation for all flow matching experiments with reproducible training behavior.
Output: TrainingConfig dataclass, EarlyStopping class, EMAModel class, FlowTrainer class with train/validate methods.
</objective>

<execution_context>
@/home/prusek/.claude/get-shit-done/workflows/execute-plan.md
@/home/prusek/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-training-infrastructure/02-CONTEXT.md
@.planning/phases/02-training-infrastructure/02-RESEARCH.md
@.planning/phases/01-data-pipeline/01-02-SUMMARY.md

# Existing patterns to follow
@rielbo/train_flow.py
@study/data/dataset.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create config and utility modules</name>
  <files>
    study/flow_matching/config.py
    study/flow_matching/utils.py
  </files>
  <action>
Create the config and utilities modules:

**config.py** - TrainingConfig dataclass:
- Fields: arch (str), flow (str), dataset (str), aug (str), group (str)
- Training params: epochs, batch_size, lr, warmup_steps (default 1000)
- EMA decay: 0.9999 (locked), grad_clip: 1.0 (locked)
- Early stopping: patience=20 (locked), min_delta=0.0
- Validation: val_frequency=1 (every epoch)
- Paths: checkpoint_dir, stats_path (default: "study/datasets/normalization_stats.pt")
- Method: `run_name` property that returns `{arch}-{flow}-{dataset}-{aug}`
- Method: `to_dict()` for Wandb config logging
- Method: `validate_stats_path()` that checks stats_path file exists and raises ValueError if not

**utils.py** - Training utilities:
1. EarlyStopping class (copy pattern from RESEARCH.md):
   - `__init__(patience=20, min_delta=0.0)`
   - `__call__(val_loss) -> bool` returns True if improved
   - `should_stop` property, `best_loss` attribute
   - `reset()` method for reuse

2. EMAModel class (port from rielbo/train_flow.py):
   - Same implementation but add `restore()` method to swap back original params
   - `state_dict()` and `load_state_dict()` for checkpointing

3. get_cosine_schedule_with_warmup (port from rielbo/train_flow.py):
   - Linear warmup for num_warmup_steps
   - Cosine decay after warmup
   - min_lr_ratio=0.1

Add `__init__.py` with public exports.
  </action>
  <verify>
```bash
cd /home/prusek/NLP && uv run python -c "
from study.flow_matching.config import TrainingConfig
from study.flow_matching.utils import EarlyStopping, EMAModel, get_cosine_schedule_with_warmup
import os

# Test config
config = TrainingConfig(arch='mlp', flow='icfm', dataset='5k', aug='none', group='test')
assert config.run_name == 'mlp-icfm-5k-none'
assert config.ema_decay == 0.9999
assert config.patience == 20
assert config.stats_path == 'study/datasets/normalization_stats.pt'
print('Config OK')

# Test stats_path validation
if os.path.exists(config.stats_path):
    config.validate_stats_path()  # Should not raise
    print('Stats path validation OK')
else:
    print('Stats file not found - validation will fail (expected if file missing)')

# Test EarlyStopping
es = EarlyStopping(patience=3)
assert es(0.5) == True   # improved
assert es(0.4) == True   # improved
assert es(0.45) == False  # not improved
assert es(0.46) == False  # not improved
assert es(0.47) == False  # not improved
assert es.should_stop == True
print('EarlyStopping OK')

# Test EMAModel with dummy
import torch.nn as nn
model = nn.Linear(10, 10)
ema = EMAModel(model, decay=0.9999)
ema.update(model)
assert len(ema.state_dict()) > 0
print('EMAModel OK')

# Test scheduler
import torch
opt = torch.optim.Adam([torch.zeros(1, requires_grad=True)], lr=1e-3)
scheduler = get_cosine_schedule_with_warmup(opt, 10, 100)
for _ in range(100):
    scheduler.step()
print('Scheduler OK')

print('ALL CHECKS PASSED')
"
```
  </verify>
  <done>
TrainingConfig has all required fields with locked defaults including stats_path.
stats_path validation method exists and works.
EarlyStopping correctly tracks patience and best loss.
EMAModel correctly shadows parameters.
Cosine schedule with warmup works.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create FlowTrainer class</name>
  <files>
    study/flow_matching/trainer.py
  </files>
  <action>
Create FlowTrainer class that orchestrates training:

**FlowTrainer class:**
```python
class FlowTrainer:
    def __init__(
        self,
        model: nn.Module,
        config: TrainingConfig,
        train_dataset: FlowDataset,
        val_dataset: FlowDataset,
        device: torch.device,
    ):
```

Key methods:

1. `_setup()` - Initialize internals:
   - Move model to device FIRST, then create EMAModel
   - Create AdamW optimizer (weight_decay=0.01)
   - Create cosine schedule with warmup
   - Create EarlyStopping
   - Create train/val DataLoaders using create_dataloader from study.data.dataset

2. `train_epoch()` -> float:
   - One epoch of flow matching training
   - Sample x0 ~ N(0,1), sample t ~ U(0,1)
   - x_t = (1-t)*x0 + t*x1, v_target = x1 - x0
   - MSE loss between model(x_t, t) and v_target
   - Gradient clipping with clip_grad_norm_
   - EMA update after each step
   - Return average epoch loss

3. `validate()` -> float:
   - Same flow matching loss computation on val set
   - Use @torch.no_grad() decorator
   - Return average validation loss

4. `train()` -> dict:
   - Main training loop
   - For each epoch: train_epoch(), validate()
   - Check early stopping, track best_loss
   - Return training summary dict

5. Properties: `global_step`, `current_epoch`, `best_val_loss`

DO NOT add Wandb or checkpoint saving yet - that's Plan 02.
Log to console with standard logging module.
  </action>
  <verify>
```bash
cd /home/prusek/NLP && CUDA_VISIBLE_DEVICES=1 uv run python -c "
import torch
import torch.nn as nn
from study.flow_matching.config import TrainingConfig
from study.flow_matching.trainer import FlowTrainer
from study.data.dataset import FlowDataset

# Simple velocity network for testing
class SimpleVelocityNet(nn.Module):
    def __init__(self, dim=1024, hidden=256):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(dim + 1, hidden),  # +1 for time
            nn.SiLU(),
            nn.Linear(hidden, dim),
        )
    def forward(self, x, t):
        t = t.unsqueeze(-1) if t.dim() == 1 else t
        return self.net(torch.cat([x, t], dim=-1))

# Load small dataset
train_ds = FlowDataset('study/datasets/splits/1k/train.pt')
val_ds = FlowDataset('study/datasets/splits/1k/val.pt')

# Create config for quick test
config = TrainingConfig(
    arch='test', flow='icfm', dataset='1k', aug='none', group='test',
    epochs=2, batch_size=64, lr=1e-3, warmup_steps=10, patience=5
)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = SimpleVelocityNet()
trainer = FlowTrainer(model, config, train_ds, val_ds, device)

# Run quick training
result = trainer.train()
print(f'Trained {result[\"epochs_run\"]} epochs')
print(f'Best val loss: {result[\"best_val_loss\"]:.4f}')
print(f'Final train loss: {result[\"final_train_loss\"]:.4f}')
assert result['epochs_run'] <= 2
assert result['best_val_loss'] > 0
print('FlowTrainer OK')
"
```
  </verify>
  <done>
FlowTrainer trains a flow matching model with EMA, gradient clipping, and early stopping.
Training loop runs without errors on GPU 1.
Validation runs every epoch.
  </done>
</task>

<task type="auto">
  <name>Task 3: Add train.py entry point with GPU verification</name>
  <files>
    study/flow_matching/train.py
  </files>
  <action>
Create CLI entry point for training:

**train.py:**
- Parse command line arguments for all TrainingConfig fields
- Required args: --arch, --flow, --dataset, --group
- Optional with defaults from config: --epochs, --batch-size, --lr, etc.
- Add --resume flag (path to checkpoint) - placeholder, implemented in Plan 02
- Add --seed for reproducibility (default 42)

Main function:
1. Set CUDA_VISIBLE_DEVICES=1 if not already set (prefer explicit in command)
2. Set random seeds (torch, numpy, random)
3. **GPU VERIFICATION (CRITICAL):**
   - Print "GPU Device: {torch.cuda.get_device_name(0)}"
   - Assert "A5000" in GPU name, or warn if different GPU
   - Print "CUDA_VISIBLE_DEVICES={os.environ.get('CUDA_VISIBLE_DEVICES', 'not set')}"
   - Verify CUDA_VISIBLE_DEVICES=1 or warn if different
4. Create TrainingConfig from args
5. Validate stats_path exists (call config.validate_stats_path())
6. Load train/val datasets using load_all_splits
7. Create model (placeholder: use SimpleVelocityNet from test)
8. Create FlowTrainer and call train()
9. Print summary

Note: Model creation will be updated in Phase 3. For now, create a simple MLP velocity network inline (same as test) to verify the pipeline works end-to-end.
  </action>
  <verify>
```bash
cd /home/prusek/NLP && CUDA_VISIBLE_DEVICES=1 uv run python -m study.flow_matching.train \
  --arch test --flow icfm --dataset 1k --group test \
  --epochs 2 --batch-size 64 --lr 1e-3 2>&1 | grep -E "(GPU Device|CUDA_VISIBLE_DEVICES|A5000|Trained|loss)" | head -10
```

Expected output should include:
- "GPU Device: NVIDIA RTX A5000" (or similar A5000 name)
- "CUDA_VISIBLE_DEVICES=1"
- Training runs for 2 epochs, prints loss values, exits cleanly

```bash
# Verify GPU assignment explicitly
cd /home/prusek/NLP && CUDA_VISIBLE_DEVICES=1 uv run python -c "
import torch
import os
gpu_name = torch.cuda.get_device_name(0)
cuda_vis = os.environ.get('CUDA_VISIBLE_DEVICES', 'not set')
print(f'GPU: {gpu_name}')
print(f'CUDA_VISIBLE_DEVICES: {cuda_vis}')
assert 'A5000' in gpu_name or 'L40S' in gpu_name, f'Expected A5000 or L40S, got {gpu_name}'
assert cuda_vis == '1', f'Expected CUDA_VISIBLE_DEVICES=1, got {cuda_vis}'
print('GPU verification PASSED')
"
```
  </verify>
  <done>
train.py runs end-to-end with CLI arguments.
Training uses GPU 1 confirmed via printed GPU name (A5000 or L40S) and CUDA_VISIBLE_DEVICES=1.
Seeds are set for reproducibility.
Stats path validation runs before training starts.
Pipeline verified working before adding Wandb/checkpoints.
  </done>
</task>

</tasks>

<verification>
Full integration test:

```bash
cd /home/prusek/NLP && CUDA_VISIBLE_DEVICES=1 uv run python -c "
import torch
import os
from study.flow_matching.config import TrainingConfig
from study.flow_matching.utils import EarlyStopping, EMAModel, get_cosine_schedule_with_warmup
from study.flow_matching.trainer import FlowTrainer
from study.data.dataset import load_all_splits

print('All imports successful')

# Verify GPU
assert torch.cuda.is_available(), 'CUDA not available'
gpu_name = torch.cuda.get_device_name(0)
cuda_vis = os.environ.get('CUDA_VISIBLE_DEVICES', 'not set')
print(f'GPU: {gpu_name}')
print(f'CUDA_VISIBLE_DEVICES: {cuda_vis}')
assert 'A5000' in gpu_name or 'L40S' in gpu_name, f'Unexpected GPU: {gpu_name}'
assert cuda_vis == '1', f'Expected CUDA_VISIBLE_DEVICES=1, got {cuda_vis}'

# Verify data loading works with trainer
train_ds, val_ds, _ = load_all_splits('1k')
print(f'Datasets: train={len(train_ds)}, val={len(val_ds)}')

# Verify stats path configuration
config = TrainingConfig(arch='test', flow='icfm', dataset='1k', aug='none', group='test')
print(f'Stats path: {config.stats_path}')
if os.path.exists(config.stats_path):
    config.validate_stats_path()
    print('Stats path validation passed')

print('Phase 02-01 integration verified')
"
```
</verification>

<success_criteria>
1. TrainingConfig dataclass with all locked defaults (EMA=0.9999, patience=20, grad_clip=1.0)
2. TrainingConfig includes stats_path field with validation method
3. EarlyStopping class correctly implements patience-based stopping
4. EMAModel class shadows parameters and supports checkpointing
5. FlowTrainer runs training loop with EMA, gradient clipping, validation every epoch
6. train.py CLI entry point works with --arch, --flow, --dataset, --group args
7. All training uses GPU 1 (A5000 or L40S) via CUDA_VISIBLE_DEVICES=1 with explicit verification
8. GPU name and CUDA_VISIBLE_DEVICES printed and verified at startup
</success_criteria>

<output>
After completion, create `.planning/phases/02-training-infrastructure/02-01-SUMMARY.md`
</output>
