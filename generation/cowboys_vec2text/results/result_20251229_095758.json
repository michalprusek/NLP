{
  "timestamp": "20251229_095758",
  "method": "COWBOYS (instruction-only)",
  "args": {
    "instructions": "datasets/cowboys/instructions_100.txt",
    "grid_path": "/home/prusek/NLP/datasets/cowboys/grid_100_qend.jsonl",
    "validation": "hbbops_improved_2/data/validation.json",
    "model": "Qwen/Qwen2.5-7B-Instruct",
    "backend": "vllm",
    "skip_eval": true,
    "mcmc_steps": 500,
    "mcmc_beta": 0.1,
    "mcmc_chains": 5,
    "mcmc_warmup": 50,
    "mcmc_thinning": 10,
    "mcmc_adapt_beta": true,
    "tr_initial": 1.0,
    "tr_min": 0.1,
    "tr_max": 5.0,
    "tr_expand": 2.0,
    "tr_contract": 0.5,
    "trust_region": true,
    "retrain_interval": 10,
    "retrain_method": "rank",
    "retrain_epochs": 50,
    "no_retrain": false,
    "top_k": 25,
    "latent_dim": 32,
    "vae_epochs": 3000,
    "vae_lr": 0.001,
    "vae_patience": 30,
    "vae_cycle_weight": 2.0,
    "gp_epochs": 3000,
    "v2t_beam": 8,
    "v2t_max_length": 512,
    "v2t_no_repeat_ngram": 3,
    "v2t_repetition_penalty": 1.2,
    "max_decode": 20,
    "iterations": 1,
    "ape_instructions": 1000,
    "ape_cache": "/home/prusek/NLP/datasets/cowboys/diverse_instructions_1000.json",
    "skip_ape": false,
    "regenerate_ape": false,
    "output_dir": "generation/cowboys_vec2text/results",
    "debug": false,
    "visualize": true
  },
  "grid_best": {
    "instruction_id": 96,
    "instruction": "If this problem were a math test, what would you write as the answer?",
    "error_rate": 0.10765731614859742
  },
  "optimized": {
    "instruction": "If this problem were a math test, what would you write as the answer?",
    "error_rate": 0.10765731614859742
  },
  "iteration_history": [
    {
      "iteration": 1,
      "instruction": "Effectively address the problem: Apply empirical reasoning to explain the problem. Establish an effective basis for understanding the issue.",
      "cosine_similarity": 0.8145200610160828,
      "log_ei": -3.5648345947265625,
      "error_rate": 0.12885959813489922,
      "improved": false,
      "best_error_so_far": 0.10765731614859742,
      "mcmc_accept_rate": 0.3444,
      "trust_region_radius": 1.0,
      "gp_pred_z_opt": 0.12885959813489922,
      "gp_pred_z_inv": 0.1277146908888218,
      "gap_z_opt": 0.0,
      "gap_z_inv": 0.001144907246077409,
      "decoder_inversion_cosine": 0.9192878007888794,
      "inversion_gap_32d": 0.12409281730651855,
      "log_ei_at_opt": -3.5648345947265625,
      "log_ei_at_realized": -9.649867057800293
    }
  ],
  "improvement": 0.0,
  "vae_best_cosine": 0.8876344561576843,
  "vae_quality_metrics": {
    "cosine_mean": 0.9247496724128723,
    "cosine_std": 0.033893223851919174,
    "cosine_min": 0.7150622010231018,
    "cosine_max": 0.9799270629882812,
    "mse_mean": 0.00019596471975091845,
    "mse_std": 8.826360135572031e-05,
    "l2_relative_error": 0.37942951917648315,
    "latent_norm_mean": 1.4398095607757568,
    "latent_norm_std": 0.1567046344280243,
    "latent_var_mean": 0.05392280966043472,
    "latent_var_min": 0.03319999948143959,
    "latent_var_max": 0.08145629614591599,
    "active_dims": 32,
    "kld_mean": 135.1154022216797,
    "kld_std": 3.9200260639190674,
    "posterior_collapsed": false
  }
}