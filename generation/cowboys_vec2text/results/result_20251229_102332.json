{
  "timestamp": "20251229_102332",
  "method": "COWBOYS (instruction-only)",
  "args": {
    "instructions": "datasets/cowboys/instructions_100.txt",
    "grid_path": "/home/prusek/NLP/datasets/cowboys/grid_100_qend.jsonl",
    "validation": "hbbops_improved_2/data/validation.json",
    "model": "Qwen/Qwen2.5-7B-Instruct",
    "backend": "vllm",
    "skip_eval": true,
    "mcmc_steps": 500,
    "mcmc_beta": 0.1,
    "mcmc_chains": 5,
    "mcmc_warmup": 50,
    "mcmc_thinning": 10,
    "mcmc_adapt_beta": true,
    "tr_initial": 1.0,
    "tr_min": 0.1,
    "tr_max": 5.0,
    "tr_expand": 2.0,
    "tr_contract": 0.5,
    "trust_region": false,
    "retrain_interval": 10,
    "retrain_method": "rank",
    "retrain_epochs": 50,
    "no_retrain": false,
    "top_k": 25,
    "latent_dim": 32,
    "vae_epochs": 3000,
    "vae_lr": 0.001,
    "vae_patience": 30,
    "vae_cycle_weight": 2.0,
    "gp_epochs": 3000,
    "v2t_beam": 8,
    "v2t_max_length": 512,
    "v2t_no_repeat_ngram": 3,
    "v2t_repetition_penalty": 1.2,
    "max_decode": 20,
    "iterations": 1,
    "ape_instructions": 1000,
    "ape_cache": "/home/prusek/NLP/datasets/cowboys/diverse_instructions_1000.json",
    "skip_ape": false,
    "regenerate_ape": false,
    "output_dir": "generation/cowboys_vec2text/results",
    "debug": false,
    "visualize": false
  },
  "grid_best": {
    "instruction_id": 96,
    "instruction": "If this problem were a math test, what would you write as the answer?",
    "error_rate": 0.10765731614859742
  },
  "optimized": {
    "instruction": "If this problem were a math test, what would you write as the answer?",
    "error_rate": 0.10765731614859742
  },
  "iteration_history": [
    {
      "iteration": 1,
      "instruction": "Steps to Analyze Your Answers. I\u00e2m a professional analyser. This is a step-by-step process. To be able to give a correct answer, I will: \u00e2 Prepare your data for analysis by putting it together in three parts.",
      "cosine_similarity": 0.8292624950408936,
      "log_ei": -3.27854061126709,
      "error_rate": 0.14786895100300912,
      "improved": false,
      "best_error_so_far": 0.10765731614859742,
      "mcmc_accept_rate": 0.32,
      "trust_region_radius": null,
      "gp_pred_z_opt": 0.14786895100300912,
      "gp_pred_z_inv": 0.14777365903010886,
      "gap_z_opt": 0.0,
      "gap_z_inv": 9.52919729002577e-05,
      "decoder_inversion_cosine": 0.903831958770752
    }
  ],
  "improvement": 0.0,
  "vae_best_cosine": 0.8882079720497131,
  "vae_quality_metrics": {
    "cosine_mean": 0.9316714406013489,
    "cosine_std": 0.034997496753931046,
    "cosine_min": 0.7238879203796387,
    "cosine_max": 0.9818825125694275,
    "mse_mean": 0.00017793923325370997,
    "mse_std": 9.113930718740448e-05,
    "l2_relative_error": 0.36001649498939514,
    "latent_norm_mean": 1.477346658706665,
    "latent_norm_std": 0.13444767892360687,
    "latent_var_mean": 0.05840574577450752,
    "latent_var_min": 0.03461542725563049,
    "latent_var_max": 0.09887629002332687,
    "active_dims": 32,
    "kld_mean": 133.1330108642578,
    "kld_std": 5.301675796508789,
    "posterior_collapsed": false
  }
}