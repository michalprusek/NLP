You are an optimization algorithm generating instruction prompts for classifying Terms of Service clauses.

TASK: {task_description}

EXAMPLE CLAUSES:
{example_problems}

CATEGORIES (8 active, MULTI-LABEL classification):
0: Limitation of liability (ltd) - For what actions/events the provider claims they will not be liable?
1: Unilateral termination (ter) - Under what conditions can the provider terminate the service and/or contract?
2: Unilateral change (ch) - Under what conditions can the provider modify the service and/or the contract?
3: Arbitration (a) - Is arbitration mandatory before the case can go to court?
4: Content removal (cr) - Under what conditions can the service provider remove users' content?
5: Choice of law (law) - What law will govern the dispute settlement?
7: Contract by using (use) - Is the consumer bound by the terms of use simply by using the service?
8: Jurisdiction (j) - Where the disputes will be adjudicated? (in what courts?)

Note: Label 6 (PINC - Privacy Included: Does the scope of the consent granted to the TOS incorporate also the privacy policy?) exists in schema but has 0 examples in dataset - do NOT mention it in prompts.

CRITICAL DATASET CHARACTERISTICS:
- **90% of clauses are FAIR** (LABELS: NONE) - they are neutral/informational text (headers, metadata, general info)
- **9% have exactly 1 unfair label** - single unfair clause type
- **1% have 2+ unfair labels** - multiple unfair clause types (e.g., "LABELS: 5, 8" for jurisdiction + choice of law)
- Models must distinguish UNFAIR clauses from FAIR text - don't over-classify!
- Empty label set (LABELS: NONE) is VALID and MOST COMMON

EVALUATION SYSTEM (INVARIANT):
- Extracts labels from: "LABELS: 0, 3", "LABELS: NONE", category name mentions, or numbers in last 100 chars
- Preferred format: "LABELS: 0, 3" or "LABELS: NONE" (no brackets like [0,3])
- Primary metric: Micro-F1 (aggregated precision/recall across all labels)
- Secondary metrics: Subset Accuracy (exact match), Macro-F1 (per-category average)
- Common failures: over-predicting NONE (kills Recall), missing secondary labels, unclear output format, not checking ALL categories

PREVIOUS PROMPTS AND SCORES:
{scored_prompts}

YOUR TASK:
Generate {num_candidates} NEW instruction prompts that will achieve HIGHER accuracy.

REQUIREMENTS:
1. Each prompt must be 2-4 sentences (under 150 words - 7B models struggle with long prompts)
2. Must instruct to provide answer in format "LABELS: <comma-separated numbers>" or "LABELS: NONE" (no brackets)
3. Must emphasize that MOST clauses are FAIR (90%) - only label UNFAIR clauses
4. Must emphasize that MULTIPLE labels can apply to one clause (1% have 2+ labels)
5. Should encourage brief analysis of legal implications before classification
6. Should guide model to check ALL categories (0-5, 7-8), not just first match
7. Should help distinguish UNFAIR clauses from FAIR/informational text (critical for Recall)
8. Should help distinguish between similar categories (e.g., 5 vs 8, 1 vs 2)
9. Each prompt must be DIFFERENT from previous ones
10. Explore different strategies (reasoning-first, category checklist, legal analysis, systematic multi-label evaluation, fair-vs-unfair distinction)

OUTPUT FORMAT:
Write EXACTLY {num_candidates} prompts, one per line.
NO numbering, NO bullet points, NO explanations.
JUST the instruction prompts themselves.

EXAMPLE OUTPUT (for num_candidates=2):
Analyze this Terms of Service clause for unfair terms. MOST clauses (90%) are FAIRâ€”if so, output "LABELS: NONE". If UNFAIR, identify ALL applicable categories (can be multiple): 0=Limitation of liability, 1=Unilateral termination, 2=Unilateral change, 3=Arbitration, 4=Content removal, 5=Choice of law, 7=Contract by using, 8=Jurisdiction. Output format: "LABELS: 0, 3" or "LABELS: NONE".
Read the clause carefully and consider its legal implications. If FAIR (neutral/informational), output "LABELS: NONE". If UNFAIR, check ALL categories (0-5, 7-8) and identify every applicable one (multiple may apply). Output format: "LABELS: <numbers>" or "LABELS: NONE".

NOW GENERATE {num_candidates} NEW PROMPTS:
