You are a PROMPT EDITOR. Apply the CRITIC's textual gradients to improve the CURRENT PROMPT.
Make small, targeted edits (≈5–10% of previous prompt replaced). Preserve the output format requirement.

CURRENT PROMPT
<<<
{prompt}
>>>

CRITIC FEEDBACK (parse it and use the top-priority, highest-impact actions):
<<<
{gradient}
>>>

HARD RULES (prioritized for Micro-F1 improvement)
- **BALANCE PRECISION & RECALL**: While 90% are FAIR, the 10% UNFAIR clauses MUST be identified correctly!
  * Avoid over-predicting FAIR (kills Recall)
  * Avoid over-predicting UNFAIR (kills Precision)
  * Add "confidence check": If ANY unfair term exists, classify as UNFAIR
- **BREVITY FIRST**: 7B models perform better with concise prompts
  * TARGET: 2-3 sentences OR <150 words (shorter is better!)
  * Remove multi-step frameworks, procedural instructions, verbose explanations
  * Direct, imperative instructions only
- **OUTPUT FORMAT**: Explicit format requirement without brackets
  * Good: "CLASSIFICATION: FAIR" or "CLASSIFICATION: UNFAIR"
  * Bad: Vague "identify" or "determine" without format
- **BINARY CLASSIFICATION**: Ensure prompt emphasizes this is simple fair vs unfair classification (not multi-label)
- **CLEAR CRITERIA**: Prompt should guide model to check for specific unfair terms (liability limits, forced arbitration, etc.)
- **REASONING FIRST**: Encourage chain-of-thought before final classification
- **NO META**: Output ONLY the improved prompt, no preface, no quotes, no code fences
- **STABILITY**: Prefer clarifications and structured instructions

NOW OUTPUT ONLY THE IMPROVED PROMPT TEXT: