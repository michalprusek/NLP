{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fd9295-9c3b-40bf-8225-185fbf1e9ec6",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mJupyter cannot be started. Error attempting to locate Jupyter: Running cells with 'Python 3.13.7' requires the notebook and jupyter package.\n",
      "\u001b[1;31mInstall 'jupyter and notebook' into the Python environment. \n",
      "\u001b[1;31mCommand: 'python -m pip install jupyter notebook -U\n",
      "\u001b[1;31mor\n",
      "\u001b[1;31mconda install jupyter notebook -U'\n",
      "\u001b[1;31mClick <a href='https://aka.ms/installJupyterForVSCode'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import pickle, sys, copy, pandas, re, math\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709e1537-3bee-45b3-8c32-9936a4e7c9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3d38b4-bf1d-47c5-af27-e701e91c692d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data path - updated to use Downloads folder\n",
    "DATA_PATH = '/Users/michalprusek/Downloads/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2c3d4-e5f6-4789-a0b1-c2d3e4f5a6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an OpenAI client with your deepinfra token and endpoint\n",
    "openai = OpenAI(\n",
    "    api_key=\"Sgh76eVtGLUcsBj8jOFgNEkRxKtRszzB\", # please only use this for lab purposes; there is a strict usage limit on it\n",
    "    base_url=\"https://api.deepinfra.com/v1/openai\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e96c47d-cb8b-4000-87c7-80819d0c8e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_llm(prompt, temperature = 0.0, max_tokens = None):\n",
    "    if max_tokens is not None and max_tokens <= 0:\n",
    "        print(f'ERROR: invalid max_tokens number: {max_tokens}')\n",
    "        max_tokens = None\n",
    "    chat_completion = openai.chat.completions.create(\n",
    "        model=\"google/gemma-3-4b-it\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "    )\n",
    "    return chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f8dfac-9a17-48e1-bb10-007d5235a98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc_ids = pandas.read_csv(f'{DATA_PATH}/claudette_train.tsv', sep='\\t')['document'].unique()\n",
    "val_doc_ids = pandas.read_csv(f'{DATA_PATH}/claudette_val.tsv', sep='\\t')['document'].unique()\n",
    "test_doc_ids = pandas.read_csv(f'{DATA_PATH}/claudette_test.tsv', sep='\\t')['document'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656e10da-4a47-4820-a5b2-103ce06cd175",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_csv(f'{DATA_PATH}/tos_dataset.csv')\n",
    "df_train = df.loc[df['document'].isin(train_doc_ids)]\n",
    "df_train_neg = df_train.loc[df_train['label'] == 0]\n",
    "df_train_pos = df_train.loc[df_train['label'] == 1]\n",
    "df_val = df.loc[df['document'].isin(val_doc_ids)]\n",
    "df_test = df.loc[df['document'].isin(test_doc_ids)]\n",
    "unfairness_categories = ['A', 'CH', 'CR', 'J', 'LAW', 'LTD', 'TER', 'USE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7488f3e-dbe8-44dc-81b4-fa132c2380f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev_neg = df_train.loc[df_train['label'] == 0]\n",
    "df_dev_pos = df_train.loc[df_train['label'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c458820-e467-4511-9f3e-56a1032a4825",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_pos = df_train.loc[df_train['label'] == 1]\n",
    "df_train_pos_per_cat = {}\n",
    "for category in unfairness_categories:\n",
    "    df_train_pos_per_cat[category] = df_train.loc[df_train[category] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00e9331-cea9-429f-8fbd-9fa57f561915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_answer_instruction(n_words = 50):\n",
    "    return f'Start your answer with \"yes\" or \"no\" and then justify your response in no more than {n_words} words.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7272a85e-9d96-44ff-9a3a-2fffec2ef395",
   "metadata": {},
   "outputs": [],
   "source": [
    "yes_res = [r'^[\\s\"]?[Yy]es[\\.,\\s]']\n",
    "\n",
    "system_prompt = 'You are a legal expert on consumer protection law. Consider the following online terms of service clause: \"'\n",
    "\n",
    "legal_standards = {\n",
    "    'A': {\n",
    "        'fairness_q': 'Does this clause describe an arbitration dispute resolution process that is not fully optional to the consumer?'\n",
    "    },\n",
    "    'CH': {\n",
    "        'fairness_q': 'Does this clause specify conditions under which the service provider could amend and modify the terms of service and/or the service itself?'\n",
    "    },\n",
    "    'CR': {\n",
    "        'fairness_q': \"Does this clause indicate conditions for content removal in the service provider's full discretion, and/or at any time for any or no reasons and/or without notice nor possibility to retrieve the content.\"\n",
    "    },\n",
    "    'J': {\n",
    "        'fairness_q': \"Does this clause state that any judicial proceeding is to be conducted in a place other than the consumer's residence (i.e. in a different city, different country)?\"\n",
    "    },\n",
    "    'LAW': {\n",
    "        'fairness_q': 'Does the clause define the applicable law as different from the law of the consumer's country of residence?'\n",
    "    },\n",
    "    'LTD': {\n",
    "        'fairness_q': 'Does this clause stipulate that duties to pay damages by the provider are limited or excluded?'\n",
    "    },\n",
    "    'TER': {\n",
    "        'fairness_q': 'Does this clause stipulate that the service provider may suspend or terminate the service at any time for any or no reasons and/or without notice?'\n",
    "    },\n",
    "    'USE': {\n",
    "        'fairness_q': 'Does this clause stipulate that the consumer is bound by the terms of use of a specific service, simply by using the service, without even being required to mark that he or she has read and accepted them?'\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc811c4-40bc-419b-9773-1088907491c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{len(train_doc_ids)} / {len(val_doc_ids)} / {len(test_doc_ids)}\")\n",
    "print(f\"{len(df_train)} / {len(df_val)} / {len(df_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2380188d-d6f6-48f4-b5de-1707b1a7509f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_dataset(df, category = None, df_neg = None, balance = True, random_negatives = False, max_pos_n = None, seed = None):\n",
    "    if category is not None:\n",
    "        pos_dset = df.loc[df[category] == 1]\n",
    "    else:\n",
    "        pos_dset = df.loc[df['label'] == 1]\n",
    "    if max_pos_n is None or max_pos_n > len(pos_dset):\n",
    "        max_pos_n = len(pos_dset)\n",
    "    if max_pos_n < len(pos_dset):\n",
    "        pos_dset = pos_dset.sample(max_pos_n, random_state=seed)\n",
    "    if random_negatives:\n",
    "        if balance:\n",
    "            neg_dset = df_train.loc[df_train[category] == 0].sample(len(pos_dset), random_state=seed)\n",
    "        else:\n",
    "            neg_dset = df_train.loc[df_train[category] == 0]\n",
    "    elif df_neg is not None:\n",
    "        pass # to be extended\n",
    "    else:\n",
    "        sys.exit('ERROR: either allow random negatives or provide `df_neg`')\n",
    "    return pos_dset, neg_dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa22cff4-f0a0-416b-bab3-f79d79caee85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_prompt(pos_dset, neg_dset, prompt, response_res = yes_res, default_label = 0, extract_label = 1, log = False):\n",
    "    dsets = [[pos_dset, 1], \n",
    "             [neg_dset, 0]]\n",
    "    if log: print(f'{len(pos_dset)} / {len(neg_dset)} positive / negative samples')\n",
    "    tp, fp, tn, fn = 0, 0, 0, 0\n",
    "    fps, fns = [], []\n",
    "    for df, label in dsets:\n",
    "        for i, ex in df.iterrows():\n",
    "            index = ex.iloc[0]\n",
    "            if log: print(f'data point @ index {index}')\n",
    "            prompt = (system_prompt + ex['text'] + '\\n' + prompt +' '+make_answer_instruction())\n",
    "            gen_text = query_llm(prompt)\n",
    "            if log: print(\"P: \"+prompt)\n",
    "            if log: print(\"R: \"+gen_text)\n",
    "            is_unfair = default_label\n",
    "            for rex in response_res:\n",
    "                if re.search(rex, gen_text) is not None:\n",
    "                    is_unfair = extract_label\n",
    "            if is_unfair:\n",
    "                if log: print(f'=> Unfair: {gen_text[:50]}')\n",
    "                if label == 1:\n",
    "                    tp += 1\n",
    "                else:\n",
    "                    fp += 1\n",
    "                    if log: print(f'false positive! @{index}')\n",
    "                    fps.append({'clause': ex['text'],\n",
    "                                'index': index,\n",
    "                                'prompt': prompt,\n",
    "                                'response': gen_text,\n",
    "                                'true_label': 0,\n",
    "                                'pred_label': 1,\n",
    "                                'gradient': 'fp',\n",
    "                               })\n",
    "            else:\n",
    "                if log: print(f'Fair: {gen_text[:50]}')\n",
    "                if label == 1:\n",
    "                    fn += 1\n",
    "                    if log: print(f'false negative! @{index}')\n",
    "                    fns.append({'clause': ex['text'], \n",
    "                                'index': index,\n",
    "                                'prompt': prompt,\n",
    "                                'response': gen_text,\n",
    "                                'true_label': 1,\n",
    "                                'pred_label': 0,\n",
    "                                'gradient': 'fn',\n",
    "                               })\n",
    "                else:\n",
    "                    tn += 1\n",
    "            if log: print('===')\n",
    "    if log: print(f\"TP: {tp}, FP: {fp}, TN: {tn}, FN: {fn}\")\n",
    "    acc = (tp+tn) / (tp+tn+fp+fn)\n",
    "    prec = tp / (tp+fp) if tp+fp > 0 else 0.0\n",
    "    rec = tp / (tp+fn) if tp+fn > 0 else 0.0\n",
    "    f1 = 2* (prec * rec)/(prec + rec) if prec+rec > 0.0 else 0.0\n",
    "    return {'pos_n': len(pos_dset),\n",
    "            'neg_n': len(neg_dset),\n",
    "            'TP': tp, 'FP': fp, 'TN': tn, 'FN': fn,\n",
    "            'acc': acc, 'prec': prec, 'rec': rec, 'f1': f1,\n",
    "            'fps': fps, 'fns': fns,\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7bef51-1298-455c-bcd4-2acb06042b1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def category_experiment(df, legal_standards, df_neg = None, categories = None, max_gen_len = 50, random_negatives = True, max_pos_n = None, log=True):\n",
    "    if categories is None:\n",
    "        categories = legal_standards.keys()\n",
    "    results = {}\n",
    "    for category in categories:\n",
    "        if log: print(f'=== Testing for category `{category}` ===')\n",
    "        ls = legal_standards[category]\n",
    "        pos_sample, neg_sample = sample_dataset(df,\n",
    "                                                category,\n",
    "                                                df_neg = df_neg,\n",
    "                                                random_negatives=random_negatives,\n",
    "                                                max_pos_n=max_pos_n,\n",
    "                                                seed=42)\n",
    "        results[category] = evaluate_prompt(pos_sample,\n",
    "                                            neg_sample,\n",
    "                                            ls['fairness_q'],\n",
    "                                            log=log)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348ddf69-5c88-43fd-baf5-2bb508115c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_report(r):\n",
    "    for label in r.keys():\n",
    "        print(label)\n",
    "        print(f\"- pos_n {r[label]['pos_n']}\")\n",
    "        print(f\"- neg_n {r[label]['neg_n']}\")\n",
    "        print(f\"- prec {r[label]['prec']}\")\n",
    "        print(f\"- rec {r[label]['rec']}\")\n",
    "        print(f\"- f1 {r[label]['f1']}\")\n",
    "        print(f\"- TP {r[label]['TP']} TN {r[label]['TN']} FP {r[label]['FP']} FN {r[label]['FN']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160df04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run experiments for each unfairness category\n",
    "# WARNING: This will make API calls and may take some time!\n",
    "results = {}\n",
    "for uc in unfairness_categories:\n",
    "    results[uc] = category_experiment(df_train_pos, legal_standards, df_neg = df_train_neg, random_negatives= True, categories=[uc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b732e5f6-a9aa-48dc-8447-07cdcf00eee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results summary\n",
    "for category in unfairness_categories:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Category: {category}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    results_report(results[category])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envDL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
